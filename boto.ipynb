{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import get_model_and_tokenizer\n",
    "model, tokenizer = get_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random pages\n",
    "import random\n",
    "from utils import topk_gradient\n",
    "from data import SubsetFalconLoader\n",
    "pages = [random.randint(0, SubsetFalconLoader.max_pages) for _ in range(1)]\n",
    "        \n",
    "# Create batches of data to process using the SubsetFalconLoader with the given parameters\n",
    "batches = list(\n",
    "    SubsetFalconLoader(\n",
    "        tokenizer = tokenizer,\n",
    "        batch_size = 1, \n",
    "        sequence_length = 50,\n",
    "        rows = pages\n",
    "    )\n",
    ")\n",
    "\n",
    "# Move the model to the specified device (CPU or GPU)\n",
    "model.to('cpu')\n",
    "\n",
    "# Reset gradients in the model to zero\n",
    "model.zero_grad()\n",
    "\n",
    "# Process each batch of data\n",
    "for batch in batches:\n",
    "    # Move the batch to the specified device\n",
    "    inputs = batch.to('cpu')\n",
    "    # Pass the inputs through the model and calculate the loss\n",
    "    outputs = model(inputs, labels=inputs)\n",
    "    # Normalize the loss by the number of batches\n",
    "    outputs.loss /= len(batches)\n",
    "    # Backpropagate the loss to compute gradients\n",
    "    outputs.loss.backward()\n",
    "    # Exit the loop after processing the first batch for demonstration purposes\n",
    "    break\n",
    "\n",
    "# Extract the top-k percent gradients from the model\n",
    "gradient = topk_gradient( model, 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File committed to EC2 instance i-0b3994e1d8b4042f2 in 23.90545916557312 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import boto3\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import paramiko\n",
    "import os\n",
    "\n",
    "# EC2 instance details\n",
    "instance_name = 'i-0b3994e1d8b4042f2'\n",
    "ec2_hostname = 'ec2-3-231-208-20.compute-1.amazonaws.com'  # Placeholder for actual hostname\n",
    "ec2_username = 'ec2-user'\n",
    "private_key_path = os.path.expanduser('~/.ssh/main.pem')  # Placeholder for actual path to your private key\n",
    "\n",
    "# Save the gradient to a temporary file and automatically delete it after use\n",
    "with tempfile.NamedTemporaryFile() as tmp_file:\n",
    "    torch.save(gradient, tmp_file.name)\n",
    "\n",
    "    # Measure the time it takes to commit the file to the EC2 instance\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Establish SSH connection to the EC2 instance\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.connect(ec2_hostname, username=ec2_username, key_filename=private_key_path)\n",
    "\n",
    "    # SCP the temporary file to the EC2 instance\n",
    "    scp = paramiko.SFTPClient.from_transport(ssh.get_transport())\n",
    "    remote_path = f'/home/{ec2_username}/gradient_file.pt'  # Placeholder for actual remote path\n",
    "    scp.put(tmp_file.name, remote_path)\n",
    "    scp.close()\n",
    "    ssh.close()\n",
    "\n",
    "    # Calculate and print the commit duration\n",
    "    commit_duration = time.time() - start_time\n",
    "    print(f\"File committed to EC2 instance {instance_name} in {commit_duration} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
